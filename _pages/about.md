---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a fifth-year PhD Candidate at the [School of Artificial Intelligence and Data Science](https://saids.ustc.edu.cn/main.htm), [University of Science and Technology of China (USTC)](https://en.ustc.edu.cn/). I received my Bachelor’s degree in 2020 from the [School of Electrical and Electronic Engineering](http://seee.hust.edu.cn/) at the [Huazhong University of Science and Technology (HUST)](https://www.hust.edu.cn/). Currently, I am pursuing my Ph.D. in the [MIRA Lab](https://miralab.ai/) at USTC, under the supervision of Prof. [Jie Wang](https://miralab.ai/people/jie-wang/). My research interests include Sample-Efficient Deep Reinforcement Learning (DRL), Learning to Optimize, AI for Chips, and Efficient DRL for Large Language Model Reasoning.

Education
======

- Phd. Candidate, School of Artificial Intelligence and Data Science, University of Science and Technology of China, 2022 -
- M.S., Electronic Engineering and Information Science, University of Science and Technology of China, 2020 - 2022
- B.S.,  School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, 2016 - 2020 (GPA Ranking: **5**/358)

Honors and Awards
======
- President Excellence Award (**Top 0.5%**), Chinese Academy of Sciences, 2025
- Outstanding Graduate of the USTC (**Top 5%**), 2025
- National Scholarship, 2024 (PhD)
- Huawei Noah’s Ark Lab, Excellent Interns (**5**/400+), 2023
- IWLS 2024 Programming Contest, **3rd place**, 2024
- Outstanding Graduate of the HUST (**Top 5%**), 2020
- National MathorCup University Mathematical Modeling Challenge, **1st Prize**, 2019
- Infineon Semiconductor Scholarship, 2018 & 2019 (Top **3%**)
- National Scholarship, 2017 (Undergraduate)
- Outstanding Communist Youth League Member, 2017

Research
======

Publications
------

1. **Zhihai Wang**, Jie Wang*, Jilai Pan, Xilin Xia, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Feng Wu. Accelerating Large Language Model Reasoning via Speculative Search. **ICML 2025**. [Paper](https://arxiv.org/pdf/2505.02865) [Code](https://github.com/MIRALab-USTC/LLMReasoning-SpecSearch)

1. Runquan Gui, **Zhihai Wang**, Jie Wang*, Chi Ma, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Defu Lian, Enhong Chen, Feng Wu. HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking. **ICML 2025**. [Paper](https://arxiv.org/pdf/2505.02322)

1. **Zhihai Wang**, Jie Wang*, Xilin Xia, Dongsheng Zuo, Lei Chen, Yuzhe Ma, Jianye Hao, Mingxuan Yuan, Feng Wu. Computing Circuits Optimization via Model-Based Circuit Genetic Evolution. **ICLR 2025**. [Paper](https://openreview.net/pdf?id=KWH4UIoQKS) [Code](https://github.com/chicwzh/AI4EDA-MUTE)

1. **Zhihai Wang**, Jie Wang*, Qingyue Yang, Yinqi Bai, Xing Li, Lei Chen, Jianye Hao, Mingxuan Yuan, Bin Li, Yongdong Zhang, Feng Wu. Towards Next-Generation Logic Synthesis: A Scalable Neural Circuit Generation Framework. **NeurIPS 2024**. [Paper](https://openreview.net/pdf?id=ZYNYhh3ocW) [Code](https://github.com/MIRALab-USTC/AI4EDA_TNet)

2. Jie Wang*, **Zhihai Wang**, Xijun Li, Yufei Kuang, Zhihao Shi, Fangzhou Zhu, Mingxuan Yuan, Jia Zeng, Yongdong Zhang, Feng Wu. Learning to Cut via Hierarchical Sequence/Set Model for Efficient Mixed-Integer Programming. **IEEE TPAMI 2024**. (Student First Author) [Paper](https://ieeexplore.ieee.org/document/10607926) [Code](https://github.com/MIRALab-USTC/L2O-HEM-Torch)

3. **Zhihai Wang**, Lei Chen, Jie Wang*, Yinqi Bai, Xing Li, Xijun Li, Mingxuan Yuan, Jianye Hao, Yongdong Zhang, Feng Wu. A Circuit Domain Generalization Framework for Efficient Logic Synthesis in Chip Design. **ICML 2024 Spotlight** (Top **3.5%**). [Paper](https://openreview.net/pdf?id=1KemC8DNa0) [Code](https://github.com/MIRALab-USTC/AI4LogicSynthesis-PruneX)

4. **Zhihai Wang**, Jie Wang*, Dongsheng Zuo, Ji Yunjie, Xilin Xia, Yuzhe Ma, Jianye Hao, Mingxuan Yuan, Yongdong Zhang, Feng Wu. A Hierarchical Adaptive Multi-Task Reinforcement Learning Framework for Multiplier Circuit Design. **ICML 2024**. [Paper](https://openreview.net/pdf?id=LGz7GaUSEB) [Code](https://github.com/chicwzh/AIChips-HAVE)

5. **Zhihai Wang**, Xijun Li, Jie Wang*, Yufei Kuang, Mingxuan Yuan, Jia Zeng, Yongdong Zhang, Feng Wu. Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model. **ICLR 2023**. [Paper](https://openreview.net/pdf?id=Zob4P9bRNcK) [Code](https://github.com/MIRALab-USTC/L2O-HEM-Torch)

6. **Zhihai Wang**, Taoxing Pan, Jie Wang*, Qi Zhou. Efficient Exploration in Resource-Restricted Reinforcement Learning. **AAAI 2023**. [Paper](https://arxiv.org/abs/2212.06988) [Code](https://github.com/MIRALab-USTC/RL-RAEB)

7. **Zhihai Wang**, Jie Wang*, Qi Zhou, Bin Li, Houqiang Li. Sample-Efficient Reinforcement Learning via Conservative Model-Based Actor-Critic. **AAAI 2022**. [Paper](https://arxiv.org/abs/2112.10504) [Code](https://github.com/MIRALab-USTC/RL-CMBAC)

8. Yinqi Bai, Jie Wang*, Lei Chen, **Zhihai Wang**, Yufei Kuang, Mingxuan Yuan, Jianye Hao, Feng Wu. A Graph Enhanced Symbolic Discovery Framework For Efficient Circuit Synthesis. **ICLR 2025**. (Student Second Author) [Paper](https://openreview.net/pdf?id=EG9nDN3eGB)

9. Haotian Ling, **Zhihai Wang**, Jie Wang*. Learning to Stop Cut Generation for Efficient Mixed-Integer Linear Programming. **AAAI 2024**. [Paper](https://arxiv.org/abs/2401.17527)

10. Yufei Kuang, Xijun Li, Jie Wang*, Fangzhou Zhu, Meng Lu, **Zhihai Wang**, Jia Zeng, Houqiang Li, Yongdong Zhang, Feng Wu. Accelerate Presolve in Large-Scale Linear Programming via Reinforcement Learning. **IEEE TPAMI 2025**. [Paper](https://arxiv.org/pdf/2310.11845) [Code](https://github.com/MIRALab-USTC/L2O-RL4Presolve)

11. Lei Chen, Xing Li, Tsaras Dimitrios, **Zhihai Wang**, Yinqi Bai, Mingxuan Yuan. A General Framework for Efficient Logic Synthesis. **ISEDA 2024 Oral**. [Paper](https://ieeexplore.ieee.org/abstract/document/10617733)

12. Zhen Wang, Jie Wang*, **Zhihai Wang**, Siyuan Xu, Zijie Geng, Mingxuan Yuan, Jianye Hao. MAD-EA: A Multi-Mask Driven Evolutionary Algorithm Framework for Macro Placement Refinement. **ISEDA 2025 Oral**.

Preprint
------

1. **Zhihai Wang#**, Zijie Geng#, Zhaojie Tu#, Jie Wang*, Yuxi Qian, Zhexuan Xu, Ziyan Liu, Siyuan Xu, Zhentao Tang, Shixiong Kai, Mingxuan Yuan, Jianye Hao, Bin Li, Yongdong Zhang, Feng Wu. Benchmarking End-To-End Performance of AI-Based Chip Placement Algorithms. [Paper](https://arxiv.org/abs/2407.15026) [Code](https://github.com/MIRALab-USTC/ChiPBench)

2. Xijun Li, Fangzhou Zhu, Hui-Ling Zhen, Weilin Luo, Meng Lu, Yimin Huang, Zhenan Fan, Zirui Zhou, Yufei Kuang, **Zhihai Wang**, Zijie Geng, Yang Li, Haoyang Liu, Zhiwu An, Muming Yang, Jianshu Li, Jie Wang, Junchi Yan, Defeng Sun, Tao Zhong, Yong Zhang, Jia Zeng, Mingxuan Yuan, Jianye Hao, Jun Yao, Kun Mao. Machine Learning Insides OptVerse AI Solver: Design Principles and Applications. [Paper](https://arxiv.org/pdf/2401.05960)

3. Qingyue Yang, Jie Wang*, Xing Li, **Zhihai Wang**, Chen Chen, Lei Chen, Xianzhi Yu, Wulong Liu, Jianye Hao, Mingxuan Yuan, Bin Li. AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference. [Paper](https://arxiv.org/pdf/2502.04077)

Academic Services
------

Invited as a reviewer/PC member for conferences, including ICLR 2023, NeurIPS 2023, ICLR 2024, ICML 2024, NeurIPS 2024, ICLR 2025, AISTATS 2025, ICML 2025, NeurIPS 2025. 

Projects
======
- Awesome DeepSeek-R1: A collection of the recent reproduction papers and projects on DeepSeek-R1. [Github](https://github.com/haoyangliu123/awesome-deepseek-r1)

Experience
======

- Noah’s Ark Lab, Huawei Technologies, Research Intern, 2022/06 - 